{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaci√≥n de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T15:46:37.408233Z",
     "start_time": "2025-06-07T15:46:36.060176Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import optuna\n",
    "from scripts import *\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T15:46:37.464883Z",
     "start_time": "2025-06-07T15:46:37.462057Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.1)\n",
    "sns.set_context(\"notebook\", rc={\"figure.figsize\": (12, 6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 50\n",
    "n_jobs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T15:46:37.476614Z",
     "start_time": "2025-06-07T15:46:37.474368Z"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset_path = './datasets/full_dataset.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_periods = ['201911', '201912']\n",
    "test_periods = ['201910']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T15:46:40.830048Z",
     "start_time": "2025-06-07T15:46:37.495444Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_parquet(full_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['cat1'] = df_full['cat1'].astype('category')\n",
    "df_full['cat2'] = df_full['cat2'].astype('category')\n",
    "df_full['cat3'] = df_full['cat3'].astype('category')\n",
    "df_full['brand'] = df_full['brand'].astype('category')\n",
    "df_full['sku_size'] = df_full['sku_size'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test = df_full[~df_full['periodo'].isin(future_periods)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_test[~df_train_test['periodo'].isin(test_periods)]\n",
    "df_test = df_train_test[df_train_test['periodo'].isin(test_periods)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future = df_full[df_full['periodo'].isin(future_periods)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_full\n",
    "del df_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df_train.columns if col not in ['target', 'weight_col', 'w_volumen', 'w_rank', 'w_tn', 'periodo', 'periodo_dt', 'year', 'customer_id', 'product_id', 'customer_id_limited', 'product_id_limited']]\n",
    "categorical_cols = ['cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'customer_id_limited_encoded', 'product_id_limited_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T15:50:40.997512Z",
     "start_time": "2025-06-07T15:50:32.829330Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df_train[features]\n",
    "y_train = df_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"device\": \"gpu\",\n",
    "        \"objective\": \"regression\",\n",
    "        \"boosting_type\": \"gbdt\", \n",
    "        \"metric\": \"rmse\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 100),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 100),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
    "        'linear_tree': True,\n",
    "        'lambda_l1': trial.suggest_float(\"lambda_l1\", 0.0, 1.0),\n",
    "        'lambda_l2': trial.suggest_float(\"lambda_l2\", 0.0, 1.0),\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        tfe_scores = []\n",
    "        mape_scores = []\n",
    "\n",
    "        sorted_periods = sorted(df_train['periodo'].unique())\n",
    "        \n",
    "        num_boost_round = trial.suggest_int('num_boost_round', 1000, 3000)\n",
    "        early_stopping_rounds = trial.suggest_int('early_stopping_rounds', 100, 300)\n",
    "        train_window = trial.suggest_int('train_window', 6, 24)\n",
    "        val_window = 2\n",
    "\n",
    "        # Weights\n",
    "        w1_alpha = trial.suggest_categorical(\"w1_alpha\", [0, 1])\n",
    "        w2_alpha = trial.suggest_categorical(\"w2_alpha\", [0, 1])\n",
    "\n",
    "        weight_all = (\n",
    "            w1_alpha * df_train[\"w_rank\"] +\n",
    "            w2_alpha * df_train[\"w_tn\"]\n",
    "        )\n",
    "\n",
    "        print(f\"Trial {trial.number}\")\n",
    "        print(f\"Entrenando {len(sorted_periods) - train_window - val_window + 1} periodos\")\n",
    "        print(f\"Num boost round: {num_boost_round}\")\n",
    "        print(f\"Early stopping rounds: {early_stopping_rounds}\")\n",
    "        print(f\"Train window: {train_window}\")\n",
    "        print(f\"Val window: {val_window}\")\n",
    "        print(f\"Pesos: w_rank: {w1_alpha} w_tn: {w2_alpha}\")    \n",
    "\n",
    "        for i in range(len(sorted_periods) - train_window - val_window + 1):        \n",
    "            train_periods = sorted_periods[i : i + train_window]\n",
    "            val_periods = sorted_periods[i + train_window : i + train_window + val_window]\n",
    "\n",
    "            train_mask = df_train['periodo'].isin(train_periods)\n",
    "            val_mask = df_train['periodo'].isin(val_periods)\n",
    "\n",
    "            X_train_wf = X_train[train_mask]\n",
    "            y_train_wf = y_train[train_mask]\n",
    "            X_val_wf = X_train[val_mask]\n",
    "            y_val_wf = y_train[val_mask]\n",
    "\n",
    "            if X_train_wf.empty or X_val_wf.empty:\n",
    "                continue\n",
    "\n",
    "            train_weights = weight_all.loc[train_mask]\n",
    "            val_weights = weight_all.loc[val_mask]\n",
    "\n",
    "            if train_weights.sum() == 0 or val_weights.sum() == 0:\n",
    "                train_data_wf = lgb.Dataset(\n",
    "                    X_train_wf,\n",
    "                    label=y_train_wf,\n",
    "                    categorical_feature=categorical_cols\n",
    "                )\n",
    "                val_data_wf = lgb.Dataset(\n",
    "                    X_val_wf,\n",
    "                    label=y_val_wf,\n",
    "                    categorical_feature=categorical_cols\n",
    "                )\n",
    "            else:\n",
    "                train_data_wf = lgb.Dataset(\n",
    "                    X_train_wf,\n",
    "                    label=y_train_wf,\n",
    "                    weight=train_weights,\n",
    "                    categorical_feature=categorical_cols\n",
    "                )\n",
    "                val_data_wf = lgb.Dataset(\n",
    "                    X_val_wf,\n",
    "                    label=y_val_wf,\n",
    "                    weight=val_weights,\n",
    "                    categorical_feature=categorical_cols\n",
    "                )\n",
    "\n",
    "            model_wf = lgb.train(\n",
    "                params,\n",
    "                train_set=train_data_wf,\n",
    "                valid_sets=[val_data_wf],\n",
    "                num_boost_round=num_boost_round,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_rounds, verbose=True)]\n",
    "            )\n",
    "\n",
    "            y_pred_wf = model_wf.predict(X_val_wf, num_iteration=model_wf.best_iteration)\n",
    "\n",
    "            tfe = np.sum(np.abs(y_val_wf - y_pred_wf)) / np.sum(np.abs(y_val_wf))\n",
    "            tfe_scores.append(abs(tfe))\n",
    "\n",
    "            mape = np.mean(np.abs((y_val_wf - y_pred_wf) / y_val_wf))\n",
    "            mape_scores.append(mape)\n",
    "            \n",
    "            print(f\"Trial {trial.number} - Finalizado ciclo {i + 1} de {len(sorted_periods) - train_window - val_window + 1} - MAPE: {mape:.3f} - TFE: {tfe:.3f}\")\n",
    "\n",
    "        print(f\"MAPE avg: {np.mean(mape_scores):.3f}\")\n",
    "        print(f\"TFE avg: {np.mean(tfe_scores):.3f}\")\n",
    "\n",
    "        return np.mean(tfe_scores)\n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} - Error: {e}\")\n",
    "        return np.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = 'lightgbm_forecast_opt'\n",
    "storage = 'sqlite:///optuna.db'\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name=study_name,\n",
    "    storage=storage,\n",
    "    load_if_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=n_trials, n_jobs=n_jobs, show_progress_bar=True)\n",
    "\n",
    "print(\"Mejores hiperpar√°metros encontrados:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[features]\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params.copy()\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params.copy()\n",
    "\n",
    "best_params['device'] = 'gpu'\n",
    "best_params['objective'] = 'regression'\n",
    "best_params['boosting_type'] = 'gbdt'\n",
    "best_params['metric'] = 'rmse'\n",
    "\n",
    "train_window = best_params.pop(\"train_window\")\n",
    "val_window = 2\n",
    "num_boost_round = best_params.pop(\"num_boost_round\")\n",
    "early_stopping_rounds = best_params.pop(\"early_stopping_rounds\")\n",
    "\n",
    "w1_alpha = best_params.pop(\"w1_alpha\")\n",
    "w2_alpha = best_params.pop(\"w2_alpha\")\n",
    "\n",
    "train_weights = (\n",
    "    w1_alpha * df_train[\"w_rank\"] +\n",
    "    w2_alpha * df_train[\"w_tn\"]\n",
    ")\n",
    "\n",
    "test_weights = (\n",
    "    w1_alpha * df_test[\"w_rank\"] +\n",
    "    w2_alpha * df_test[\"w_tn\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_weights.sum() == 0 or test_weights.sum() == 0:\n",
    "    train_data_final = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_cols)\n",
    "    test_data_final = lgb.Dataset(X_test, label=y_test, categorical_feature=categorical_cols)\n",
    "else:\n",
    "    train_data_final = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_cols, weight=train_weights)\n",
    "    test_data_final = lgb.Dataset(X_test, label=y_test, categorical_feature=categorical_cols, weight=test_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.train(\n",
    "    best_params,\n",
    "    train_set=train_data_final,\n",
    "    valid_sets=[test_data_final],\n",
    "    num_boost_round=num_boost_round,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_rounds, verbose=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe_train = np.sum(np.abs(y_train - y_pred_train)) / np.sum(np.abs(y_train))\n",
    "tfe_test = np.sum(np.abs(y_test - y_pred_test)) / np.sum(np.abs(y_test))\n",
    "\n",
    "print(f'Total Forecast Error en entrenamiento: {tfe_train:.4f}')\n",
    "print(f'Total Forecast Error en prueba: {tfe_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pd.DataFrame(y_pred_train, columns=['target_predicted'], index=X_train.index)\n",
    "y_pred_test = pd.DataFrame(y_pred_test, columns=['target_predicted'], index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.index, 'target_predicted'] = y_pred_train['target_predicted']\n",
    "df_test.loc[df_test.index, 'target_predicted'] = y_pred_test['target_predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('modelo_lgb.txt')\n",
    "print(\"Modelo guardado exitosamente como 'modelo_lgb.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = model.feature_name()\n",
    "\n",
    "importance_gain = model.feature_importance(importance_type='gain')\n",
    "importance_split = model.feature_importance(importance_type='split')\n",
    "\n",
    "df_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'gain': importance_gain,\n",
    "    'split': importance_split\n",
    "}).sort_values(by='gain', ascending=False)\n",
    "\n",
    "df_importance.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = df_importance[df_importance['gain'] == 0]['feature'].tolist()\n",
    "\n",
    "print(\"Features a eliminar (gain = 0):\")\n",
    "for feature in features_to_remove:\n",
    "    print(f\"- {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance.head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
